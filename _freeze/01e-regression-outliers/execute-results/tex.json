{
  "hash": "faa7fdc3a1747416153e24f2b490636b",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Introduction to Statistical Modeling\"\nsubtitle: \"Outliers\"\nauthor: \"Joris Vankerschaver\"\npdf-engine: lualatex\nformat:\n  beamer:\n    theme: Pittsburgh\n    colortheme: default\n    fonttheme: default\n    include-in-header:\n      - file: header.tex\n---\n\n\n\n\n## Outliers / Influential observations \n\n- Dataset often contains extreme values for outcome $Y$ and/or predictors $X$\n- These **can** influence regression line strongly (but don't have to)\n\n## Influence of influential observations \n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](01e-regression-outliers_files/figure-beamer/unnamed-chunk-2-1.pdf){fig-align='center' width=4in height=3.5in}\n:::\n:::\n\n\n## Influence of influential observations \n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](01e-regression-outliers_files/figure-beamer/unnamed-chunk-3-1.pdf){fig-align='center' width=4in height=3.5in}\n:::\n:::\n\n\n\n## Influence of influential observations \n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](01e-regression-outliers_files/figure-beamer/unnamed-chunk-4-1.pdf){fig-align='center' width=4in height=3.5in}\n:::\n:::\n\n\n## Influence of influential observations \n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](01e-regression-outliers_files/figure-beamer/unnamed-chunk-5-1.pdf){fig-align='center' width=4in height=3.5in}\n:::\n:::\n\n\n## Tracking influential observations\n\n**Residuals**:\n\n- Indicate how far outcome deviates from regression line\n- Normally distributed with mean 0 and variance $\\sigma^2 = MSE$.\n\nHence, can be used to identify extreme outcomes:\n\n- 95% of residuals expected in interval $[-2\\sigma, 2\\sigma]$\n- Observations where residual is much larger are probably outliers.\n\n## Exteme outcomes in analysis larches?\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](01e-regression-outliers_files/figure-beamer/unnamed-chunk-6-1.pdf){fig-align='center' width=4in height=3.5in}\n:::\n:::\n\n\n## Tracking influential observations\n\n- **Scatterplots** of outcome in function of predictors can be used to identify extreme outcomes and predictors\n- When multiple predictors, these plots have serious shortcomings\n\n## Multivariate outliers: $Y$ versus $X_1$ or $X_2$\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](01e-regression-outliers_files/figure-beamer/unnamed-chunk-7-1.pdf){fig-align='center' width=4in height=3.5in}\n:::\n:::\n\n\n\n## Multivariate outliers: $X_1$ versus $X_2$\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](01e-regression-outliers_files/figure-beamer/unnamed-chunk-8-1.pdf){fig-align='center' width=4in height=3.5in}\n:::\n:::\n\n\n\n## Leverage\n\n- Diagnostic measure to identify influential predictor-observations\n- Data point has high leverage if it has \"extreme\" predictor values (low or high)\n\n\nMathematically: \n\n- Weighted distance between predictor for observation $i$ and mean predictor.\n- How much the $i$th observed value affects the $i$th fitted value:\n$$\n  h_{ii} = \\frac{\\partial \\hat{y}_i}{\\partial y_i}.\n$$\n\n\n## Interpretation of leverage\n\n- If high leverage for $i^{th}$ observation, then\n  - it has predictor values that deviate strongly from the mean\n  - it **possibly** has large influence on regression coefficients and predictions\n\n- Leverage is on average $p/n$ with $p$ number of unknown parameters\n- **Extreme leverage**: larger than $2p/n$\n\n## Leverage in analysis of larches\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](01e-regression-outliers_files/figure-beamer/unnamed-chunk-9-1.pdf){fig-align='center' width=4in height=3.5in}\n:::\n:::\n\nNote: larches model has $p = 7$, so $2p/n = 0.54$.\n\n## Cook's distance\n\n- Diagnostic measure for influence of $i^{th}$ observation on all predictions / estimated coefficients.\n- Cook's distance for $i^{th}$ observation is obtained by comparing each prediction $\\hat{Y}_j$ with prediction $\\hat{Y}_{j(i)}$ that would be obtained **if $i^{th}$ observation was deleted**:\n$$\n  D_i=\\frac{\\sum_{j=1}^n(\\hat{Y}_j-\\hat{Y}_{j(i)})^2}{p \\cdot\\mathrm{MSE}}\n$$ \n\n## Interpretation Cook's distance\n\n- If Cook's distance $D_i$ large, then $i^{th}$ observation has large influence on predictions and coefficients\n- **Extreme Cook's distance**: exceeds  50\\% percentile of $F_{p,n-p}$-distribution\n\nExample:\n\n- In analysis of larches is $p=7, n=26$ and the 50\\% percentile of $F_{p,n-p}$-distribution 0.94\n- Cook's distance of first observation is 1.5 and corresponds to 77\\% percentile\n- Conclusion: first observation has large influence on estimated regression coefficients \n\n## Cook's distance in analysis of larches\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](01e-regression-outliers_files/figure-beamer/unnamed-chunk-10-1.pdf){fig-align='center' width=4in height=3.5in}\n:::\n:::\n\n\n## Analysis of larches: residual plots\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](01e-regression-outliers_files/figure-beamer/unnamed-chunk-11-1.pdf)\n:::\n:::\n\n\n## DFBETAs\n\nOn what coefficient(s) will first observation have large influence?\n\n- Diagnostic measure for influence of $i^{th}$ observation **on each regression coefficient separately**\n- DFBETAs for $i^{th}$ observation and $j^{th}$ coefficient is obtained by comparing $j^{th}$ coefficient $\\hat{\\beta}_j$ with coefficient $\\hat{\\beta}_{j(i)}$ from model **if $i^{th}$ observation would have been deleted**\n$$\n  \\textrm{DFBETA}_{j(i)}=\\frac{\\hat{\\beta}_{j}-\\hat{\\beta}_{j(i)}}{\\textrm{SD}(\\hat{\\beta}_{j})}\n$$ \n\n\n## Interpretation DFBETAs\n\n- Sign indicates if deleting observation $i$ causes an increase (DFBETA$<0$) or decrease (DFBETA$>0$) in each coefficient\n- **Extreme DFBETAs**: exceeds 1 in small to moderate datasets, and $2/\\sqrt{n}$ in large datasets\n\n## DFBETAs in analysis of larches\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](01e-regression-outliers_files/figure-beamer/unnamed-chunk-12-1.pdf){fig-align='center' width=4in height=3.5in}\n:::\n:::\n\n\n## DFBETAs in analysis of larches\n\nFirst observation has **large influence on interaction between phosphorus and residual ash**:\n\n- current coefficient is -598.08 (SE 290.02);\n- DFBETA is 2.17;\n- after deletion of first observation, interaction between phosphorus and residual ash will be around\n$$\n  -598.08-2.17\\times 290.02=-1227.42\n$$\n\n\n## Histogram and QQ-plot of interaction\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](01e-regression-outliers_files/figure-beamer/unnamed-chunk-13-1.pdf){fig-align='center' width=4in height=3.5in}\n:::\n:::\n\n\n## Analysis of larches after deletion $1^{st}$ observation\n\n\\small\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n                      Estimate Std. Error    t value    Pr(>|t|)\n(Intercept)           101.8433  170.89955  0.5959248 0.558645291\nnitrogen2            -194.2135  105.36608 -1.8432260 0.081826133\nphosphor2            -911.1361  686.55995 -1.3271035 0.201063465\npotassium2            132.9597   41.41191  3.2106631 0.004847492\nresidu2               332.9542  159.95466  2.0815538 0.051930532\nnitrogen2:phosphor2  1179.3050  429.71839  2.7443671 0.013331564\nphosphor2:residu2   -1225.6303  665.87615 -1.8406279 0.082222531\n```\n\n\n:::\n:::\n\n\n## Analysis of larches after deletion interaction\n\n\\small\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n                     Estimate Std. Error    t value    Pr(>|t|)\n(Intercept)         134.47244   182.5540  0.7366172 0.469908260\nnitrogen            -66.35461    94.9178 -0.6990744 0.492556067\nphosphor          -1024.58992   736.3183 -1.3915041 0.179357766\npotassium           128.83662    44.2072  2.9143806 0.008574138\nresidu               23.51194    36.0929  0.6514284 0.522185637\nnitrogen:phosphor   661.49644   370.7815  1.7840600 0.089594772\n```\n\n\n:::\n:::\n\n\n## Analysis of larches: final model\n\n\\small\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n                     Estimate Std. Error    t value    Pr(>|t|)\n(Intercept)         160.66283  175.61424  0.9148622 0.370649894\nnitrogen            -76.49677   92.34000 -0.8284250 0.416746264\nphosphor          -1120.70470  711.42841 -1.5752881 0.130135986\npotassium           138.06170   41.29966  3.3429260 0.003084272\nnitrogen:phosphor   724.38231  353.05353  2.0517634 0.052870451\n```\n\n\n:::\n:::\n\n\n## Final analysis: leverage\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](01e-regression-outliers_files/figure-beamer/unnamed-chunk-20-1.pdf){fig-align='center' width=4in height=3.5in}\n:::\n:::\n\n\n## Final analysis: Cook's distance\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](01e-regression-outliers_files/figure-beamer/unnamed-chunk-21-1.pdf){fig-align='center' width=4in height=3.5in}\n:::\n:::\n\n\n## Final analysis: residual plots\n\n\\centering\n\n::: {.cell}\n::: {.cell-output-display}\n![](01e-regression-outliers_files/figure-beamer/unnamed-chunk-22-1.pdf)\n:::\n:::",
    "supporting": [
      "01e-regression-outliers_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": null,
    "postProcess": false
  }
}