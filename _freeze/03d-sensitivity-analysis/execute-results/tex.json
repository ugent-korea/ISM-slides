{
  "hash": "e869c3840adbd052bd33eef724d295cb",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Nonlinear Modeling: Sensitivity Analysis\"\nsubtitle: Introduction to Statistical Modelling\nauthor: Prof. Joris Vankerschaver\npdf-engine: lualatex\nformat:\n  beamer:\n    theme: Pittsburgh\n    colortheme: default\n    fonttheme: default\n    header-includes: |\n      \\setbeamertemplate{frametitle}[default][left]\n      \\setbeamertemplate{footline}[frame number]\n      \\usepackage{emoji}\n      \\usepackage{luatexko}\n\n---\n\n\n\n\n# Sensitivity Analysis\n\n## Why sensitivity analysis?\n\n- Verify what _sources of uncertainty_ contribute most to variance (uncertainty) of model output.\n- Sources of uncertainty in model can be\n    - Model parameters, initial conditions, inputs\n    - Model structure\n- Better understand changes in model predictions due to the above\n\n## Why sensitivity analysis?\n\n- Detect what _model parameters_ contribute most to model output uncertainty \n- Want to reduce model uncertainty, so best to focus on most influential parameters \n- Gives idea of correlation between parameters \n- Helps in choice of what parameters to estimate (in parameter estimation)\n\n## Why sensitivity analysis?\n\n- Gives information about interesting location, time, ... to collect experimental data\n- Basis for experimental design\n- Gives information on insensitive model parameters\n- Useful in model reduction of overparametrized models\n\n## Local vs global\n\n1. Local sensitivity analysis\n    - Determine sensitivity at **one certain point** in parameter space\n    - Not very computationally intensive\n2. Global sensitivity analysis\n    - Determine sensitivity in **delimited area** of parameter space\n    - Usually gives a mean sensitivity\n    - Can become extremely computationally intensive\n\n- Each technique has advantages and disadvantages\n- Each technique gives different type of information\n    \n\n## Examples of sensitivity analysis: water quality model\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\n- Hundreds of parameters\n- Each model simulation takes days to run\n- Identifying highly sensitive parameters is critical\n\n![](./images/03e-sensitivity/wqm-model.png){fig-align=\"center\" width=75% align=\"center\"}\n:::\n\n::: {.column width=\"50%\"}\n\n![](./images/03e-sensitivity/wqm-river.png){width=75%}\n![](./images/03e-sensitivity/wqm-parameters.png){width=75%}\n:::\n::::\n\n\\scriptsize\nSource: *Developing a cloud-based toolbox for sensitivity analysis of a water quality model* (S. Kim et al, Environmental Modeling and Software, 2021)\n\n## Examples of sensitivity analysis: cell signaling\n\nToll-like signaling pathway:\n\n- Cellular response to external stimuli (e.g. infection)\n- Central role for NF-$\\kappa$B transcription factor\n- Shuttles back and forth between cytoplasm and nucleus\n\n![](./images/03e-sensitivity/nf-kappa-b-model.png){fig-align=\"center\" width=60%}\n\n\\scriptsize    \nSource: Images from _Fundamentals of Systems Biology_, M. Covert, CRC Press, 2014.\n\n## Examples of sensitivity analysis: cell signaling\n\nHoffmann-Levchenko (2005): Computational model for NF-$\\kappa$B\n\n- 25 ODEs, 36 parameters\n- Models protein production, degradation, transport\n- Important role for **parameter estimation** and **sensitivity analysis**\n\n\n![](./images/03e-sensitivity/nf-kappa-b-equations.png){fig-align=\"center\" height=\"50%\"}\n\n\n\\scriptsize    \nSource: Images from _Fundamentals of Systems Biology_, M. Covert, CRC Press, 2014.\n\n## Examples of sensitivity analysis: cell signaling\n\nSensitivity analysis: which parameters affect the model the most?\n\n- Transcription rate: affects output a lot (**sensitive**)\n- Degradation rate: relatively **insensitive**\n\nGives rough idea, needs to be corroborated with full model.\n\n:::: {.columns}\n::: {.column width=\"50%\"}\n![](./images/03e-sensitivity/nf-kappa-b-oscillations.png){width=90%}\n:::\n\n::: {.column width=\"50%\"}\n![](./images/03e-sensitivity/nf-kappa-b-sensitivity.png)\n:::\n::::\n\n\\scriptsize    \nSource: Images from _Fundamentals of Systems Biology_, M. Covert, CRC Press, 2014.\n\n# Local sensitivity analysis    \n\n## Local sensitivity analysis\n\nHow sensitive is model output ($y$) to changes of model parameter ($\\theta$) *at one single point* in parameter space?\n\n- **(Absolute) local sensitivity**: partial derivative of variable with respect to parameter at single point in parameter space\n$$\n  S(\\theta, x) = \\frac{\\partial y}{\\partial \\theta}(\\theta, x)\n$$\n- If $k$ parameters, then also $k$ sensitivity functions:\n$$\n  S_i(\\theta, x) = \\frac{\\partial y}{\\partial \\theta_i}(\\theta, x), \\quad\n  i = 1, \\ldots, k.\n$$\n\n## Local sensitivity analysis: absolute sensitivity\n\n**Problem**: often very hard to compute partial derivative analytically.\n\n**Solution**: compute derivative **numerically** through finite difference method:\n\n- Forward difference:\n$$\n\\left.\\frac{\\Delta y}{\\Delta \\theta_j}\\right|_+  \n  =  \\frac{y(x,\\theta_j+\\Delta\\theta_j)-y(x,\\theta_j)}{\\Delta\\theta_j}\n$$\n- Backward difference:\n$$\n\\left.\\frac{\\Delta y}{\\Delta \\theta_j}\\right|_-  \n  = \\frac{y(x,\\theta_j)-y(x,\\theta_j-\\Delta\\theta_j)}{\\Delta\\theta_j}\n$$\n\n\n## Local sensitivity analysis: absolute sensitivity\n\n- How to choose perturbation $\\Delta\\theta_j$?\n  - Too large: approximation is not good\n  - Too small: numerical instabilities.\n- In practice, choose $\\Delta \\theta_j$ **small** and **fixed**, e.g.\n$$\n   \\Delta \\theta_j = 10^{-6}.\n$$\n\n::: {.callout-tip}\n## Convergence\n  Both the forward and the backward difference agree with the derivative up to **first order** in $\\Delta \\theta_j$:\n$$\n  \\frac{\\partial y(x)}{\\partial \\theta_j} = \n    \\left.\\frac{\\Delta y(x)}{\\Delta \\theta_j}\\right|_+\n    + \\mathcal{O}(\\Delta \\theta_j), \\quad\n  \\frac{\\partial y(x)}{\\partial \\theta_j} = \n    \\left.\\frac{\\Delta y(x)}{\\Delta \\theta_j}\\right|_-  \n    + \\mathcal{O}(\\Delta \\theta_j).\n$$\n:::\n\n\n## Local sensitivity analysis: absolute sensitivity\n\n- Third option: central difference\n$$\n\\frac{\\Delta y(x)}{\\Delta \\theta_j} =   \n    \\frac{y(x,\\theta_j+\\Delta\\theta_j) - y(x,\\theta_j-\\Delta\\theta_j)}{2\\Delta\\theta_j}\n$$\n\n::: {.callout-tip}\n## Convergence\n  The central difference agrees with the derivative up to **second\n  order** in $\\Delta \\theta_j$:\n  $$\n  \\frac{\\partial y(x)}{\\partial \\theta_j} = \n    \\frac{\\Delta y(x)}{\\Delta \\theta_j}\n    + \\mathcal{O}((\\Delta \\theta_j)^2).\n  $$\n:::\n\n## Local sensitivity analysis: relative sensitivity\n\nAbsolute sensitivity is influenced by magnitude of variable and parameter. \n\n- Problematic if we want to compare sensitivities of different combinations of outputs and parameters \n- Use **relative sensitivity**.\n\n## Local sensitivity analysis: relative sensitivity\n\nDifferent definitions, depending on what's important:\n\n1. Relative sensitivity w.r.t. parameter:\n  $$\n    \\frac{\\partial y(t)}{\\partial \\theta_j} \\cdot \\theta_j\n  $$\n  Compare sensitivity of same variable w.r.t. *different parameters*\n2. Relative sensitivity w.r.t. variable \n  $$\n    \\frac{\\partial y_i(t)}{\\partial \\theta} \\cdot \\dfrac{1}{y_i}\n  $$ \nCompare sensitivity of *different variables* w.r.t. same parameter\n\n## Local sensitivity analysis: relative sensitivity\n\n3. Total relative sensitivity \n  $$\n    \\frac{\\partial y_i(t)}{\\partial \\theta_j} \\cdot \\dfrac{\\theta_j}{y_i}\n  $$\nCompare all sensitivities (of *different variables* w.r.t. *different parameters*)\n\n## Local sensitivity analysis\n\n- Relative sensitivities allow to **rank sensitivities**. Important for:\n    - Choice parameters for parameter estimation\n    - Choice parameters for model reduction\n    - Choice for additional measurement or experimental determination of parameter (reduce sources of uncertainty)\n- Ranking **depends on value of parameter**, can be different at different position in parameter space\n- How to compare continuous sensitivity functions?\n- Interest in specific values of independent variable\n    - Where measurements are available\n    - Where measurements will be collected\n    \n## Local sensitivity analysis\n\n- Create generic model with\n    - Time $t$ as independent variable\n    - Outputs $y_i$, $i=1,\\ldots,v$\n    - Parameters $\\theta_j$, $j=1,\\ldots,p$\n    - Moments of measurements $t_k$, $k=1,\\ldots,N$\n- Total relative sensitivity of variable $y_i$ w.r.t. parameter $\\theta_j$ at moment $t_k$\n$$\n  S_{i,j,k} = \n    \\frac{\\partial y_i(t_k)}{\\partial \\theta_j} \\cdot     \\frac{\\theta_j}{y_i}\n$$\n\n## Local sensitivity analysis\n\nImportance parameter is determined by its impact on _all_ variables \\newline\n$\\rightarrow$ sum and average over all variables \\newline\n$\\rightarrow$ take sign into account (square and root)\\newline\n__root mean square sensitivity for parameter__ $\\theta_j$\n$$\n\\delta_{j,k}^{rmsq}=\\sqrt{\\dfrac{\\sum_{i=1}^vS_{i,j,k}^2}{v}}\n$$\n\\ \\newline\n$\\delta_{j,k}^{rmsq}$ can be very variable from moment to moment \\newline\n$\\rightarrow$ sum and average over all time points\\newline\n__time mean root mean square sensitivity for parameter__ $\\theta_j$\n$$\n\\delta_j^{rmsq} = \\dfrac{1}{N}\\sum_{k=1}^N \\delta_{j,k}^{rmsq}\n$$\n\n## Local sensitivity analysis\n\n- Gives one single measure for sensitivity of parameter\n- Use this measure to determine importance of parameter\n- Obtained value depends on\n    - nominal parameter value: nonlinear models give different values at different location in parameter space (see also global sensitivity analysis)\n    - choice of time points is arbitrary: this can lead to different set of parameters that are best estimated using dataset (see also identifiability)\n- Modifications can be defined based on application/goal\n\n# Side track: Monte Carlo simulation\n\n## \n\nThese slides have been moved to the slide deck `03f-monte-carlo.pdf`\n\n## Global sensitivity analysis (GSA)\n\n- Measure for sensitivity in delimited area in parameter space\n- PDFs for parameters need to be chosen/found (same as for uncertainty analysis)\n\n3 techniques will be discussed:\n\n- Standardized regression coefficients\n- Screening techniques\n- Variance decomposition\n\n## GSA: Standardized regression coefficients\n\n- Linear regression of Monte Carlo simulations\n- Each line is simulation of variable $y$ for different parameter set $\\Theta$, i.e., other point in parameter space\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](03d-sensitivity-analysis_files/figure-beamer/unnamed-chunk-3-1.pdf){fig-align='center' width=3in height=2in}\n:::\n:::\n\n\n- Figure: 100 simulations of dissolved oxygen, with $k_1, k_2$ sampled uniformly between $0.1$ and $0.8$.\n\n## GSA: Standardized regression coefficients\n\n- Consider outcomes at fixed time $T$\n- Quantify effect of parameters $\\theta_1, \\ldots \\theta_p$ through linear model\n$$\n  y_{t = T} = b_1 \\theta_1 + \\cdots + b_p \\theta_p + \\epsilon\n$$\n- Regression coefficient $b_i$ gives contribution of parameter $\\theta_i$ in explaining variance of $y_{t = T}$\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](03d-sensitivity-analysis_files/figure-beamer/unnamed-chunk-4-1.pdf){fig-align='center' width=4.5in height=2in}\n:::\n:::\n\n\n## GSA: Standardized regression coefficients\n\n- Correct for spread on both parameter and output\n- Recalculate coefficients $b_i$ to $SRC$s\n$$\nSRC_{\\theta_i} = b_i \\cdot \\dfrac{\\sigma_{\\theta_i}}{\\sigma_y}\n$$\n- Sample standard deviations from \n  - vector $y_{t = T}$ for output\n  - parameter samples for parameter $\\theta_i$.\n\n\n## GSA: Standardized regression coefficients\n\n- For linear model in parameters that were examined, the total variance is explained by $SRC$s\n$$\\sum_i SRC_{\\theta_i}^2=1$$\n- For nonlinear models (in the parameters) _not_ all variance will be explained. The part that is explained is given by determination coefficient\n$$R^2=\\sum_{i=1}^n \\dfrac{(\\hat{y}_i-\\overline{y})^2}{(y_i-\\overline{y})^2}$$\n- $\\hat{y}_i$: prediction by regression model\n- Technique only valid if $R^2 > 0.7$\n\n## GSA: Screening techniques\n\n- Goal: obtain idea of importance of model parameters using only a limited number of simulations\n- Example of technique: Morris screening\n- Calculation of *elementary effect* for $\\theta_i$\n  $$\n    EE_{\\theta_i} = \\dfrac{y(\\theta_i+\\Delta)-y(\\theta)}{\\Delta}\n  $$\n- $\\Delta$ is a predetermined step size in parameter\n- Remark analogy with local sensitivity, however, step size much larger\n\n## GSA: Morris screening\n\n- Assume 2 parameters $\\theta_1$ and $\\theta_2$\n- Choose regions in parameter space to compute elementary effects\n- Summarize EE using mean and variance\n\n![](./images/03e-sensitivity/morris.pdf){fig-align=\"center\"}\n\n## GSA: Morris screening\n\n- Vector of $EE$ (in this case 3)\n- Statistical analysis of this vector\n    - $\\mu_{EE_{\\theta_i}}$: indication on average effect of this parameter over entire parameter space; large value means important parameter and vice versa\n    - $\\sigma_{EE_{\\theta_i}}$: information about linear behavior of parameter; large value means nonlinear parameter or parameter involved in interactions with other parameters\n- Do same for $\\theta_2$\n\n## GSA: Morris screening\n\n- Normally 2 simulations needed per $EE$\n- 1991: Morris introduced more efficient way\n- Number of simulations needed for $p$ parameters:\n  - Naive: $(2 \\times \\text{\\#EE})^p$\n  - Morris: $(p + 1) \\times \\text{\\#EE}$\n\n![](./images/03e-sensitivity/morris-2.pdf){height=\"70%\"}\n\n## GSA: Variance decomposition\n\n- Goal: find share of each model parameter in variance of model output\n- Used for models that are strongly nonlinear or nonmonotonous\n- Example of model with 3 paramaters:\n$$\n  \\sigma_y^2=\\sigma_1^2+\\sigma_2^2+\\sigma_3^2+\\sigma_{12}^2+\\sigma_{13}^2+\\sigma_{23}^2+\\sigma_{123}^2\n$$\n- Normalisation (i.e., divide by $\\sigma_y^2$) gives _sensitivity indices_\n$$\n  1=S_1+S_2+S_3+S_{12}+S_{13}+S_{23}+S_{123}\n$$\n- Indicate which fraction of total variance is determined by certain parameter or parameter combination\n\n## GSA: Variance decomposition\n\n- _Total sensitivity indices_\n\\begin{eqnarray*}\nS_{T1} & = & S_1 + S_{12} + S_{13} + S_{123} \\\\\nS_{T2} & = & S_2 + S_{12} + S_{23} + S_{123} \\\\\nS_{T3} & = & S_3 + S_{13} + S_{23} + S_{123} \n\\end{eqnarray*}\n- Give total contribution of a certain parameter, including interaction effects\n- Watch out: some contributions are counted multiple times, hence sum of all total sensitivity indices is no longer 1\n\n## GSA: Variance decomposition\n\n- Two techniques:\n    - FAST (Fourier Amplitude Sensitivity Test): uses Fourier decomposition of model output; can determine first order effects (total effects $\\rightarrow$ extendedFAST); computationally intensive ((ten) thousands of simulations)\n    - Sobol indices: uses multiple integrals, both first order and higher order effects; computationally expensive; less efficient than FAST\n\n",
    "supporting": [
      "03d-sensitivity-analysis_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": null,
    "postProcess": false
  }
}